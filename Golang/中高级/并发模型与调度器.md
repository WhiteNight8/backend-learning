# Go 并发模型与调度器

## Golang 协程 (goroutine) 的实现原理与内存模型

### Goroutine 实现原理

Goroutine 是 Go 语言的核心特性，它是一种用户态的轻量级线程。与传统的操作系统线程不同，goroutine 的管理完全由 Go 运行时控制。

#### 核心数据结构

```go
// runtime/runtime2.go 中的 g 结构体（简化版）
type g struct {
    stack       stack     // 栈内存
    stackguard0 uintptr   // 栈溢出检查
    _panic      *_panic   // panic 链表
    _defer      *_defer   // defer 链表
    m           *m        // 当前绑定的 M
    sched       gobuf     // 调度信息
    atomicstatus uint32   // 状态
    goid        int64     // goroutine ID
    startfunc   func()    // 起始函数
}

// gobuf 保存调度时的上下文
type gobuf struct {
    sp   uintptr  // 栈指针
    pc   uintptr  // 程序计数器
    g    guintptr // goroutine
    ret  uintptr  // 返回值
}
```



#### 栈管理机制

Go 使用分段栈（segmented stack）和连续栈（contiguous stack）两种策略：

1. **初始栈大小**：2KB（相比线程的 8MB 默认栈）
2. **动态增长**：通过栈拷贝实现栈扩容
3. **栈收缩**：GC 时检查并回收未使用的栈空间

### Go 内存模型

Go 内存模型定义了 goroutine 之间的内存访问规则：

#### Happens-Before 关系

```go
// 示例：channel 通信的内存同步
func producer(ch chan int) {
    data := 42    // 写操作 A
    ch <- data    // 发送操作 B
}

func consumer(ch chan int) {
    data := <-ch  // 接收操作 C
    println(data) // 读操作 D
}
```

在这个例子中，happens-before 关系保证：A → B → C → D

#### 内存屏障与可见性

Go 运行时在关键点插入内存屏障：

- Channel 操作
- Mutex 加锁/解锁
- Once.Do 调用
- Goroutine 创建和结束

## Go 调度器 GMP 模型的工作原理与演进历史

### 演进历史

#### GM 模型（Go 1.0）

- **G**：Goroutine
- **M**：Machine（OS线程）
- 问题：全局锁竞争、频繁的上下文切换

#### GPM 模型（Go 1.1+）

引入了 P（Processor）解决 GM 模型的问题：

- **G**：Goroutine
- **P**：Processor（逻辑处理器）
- **M**：Machine（OS线程）

### GMP 模型核心结构

```go
// P 结构体（简化）
type p struct {
    id          int32
    status      uint32     // 状态
    runqhead    uint32     // 本地队列头
    runqtail    uint32     // 本地队列尾
    runq        [256]guintptr // 本地运行队列
    runnext     guintptr   // 下一个要运行的 G
    gcBgMarkWorker guintptr // GC 后台标记工作者
}

// M 结构体（简化）
type m struct {
    g0      *g        // 调度栈
    curg    *g        // 当前运行的 G
    p       puintptr  // 关联的 P
    nextp   puintptr  // 下一个 P
    park    note      // 休眠信号
    spinning bool     // 是否处于自旋状态
}
```



### 调度流程

1. **本地队列优先**：P 优先从自己的本地队列获取 G
2. **全局队列补充**：本地队列为空时从全局队列获取
3. **工作窃取**：本地和全局队列都为空时，尝试从其他 P 窃取
4. **网络轮询**：检查网络 I/O 是否就绪



## 从源码角度分析 goroutine 的生命周期

### 创建过程

```go
// runtime/proc.go - newproc 函数
func newproc(siz int32, fn *funcval) {
    argp := add(unsafe.Pointer(&fn), sys.PtrSize)
    gp := getg()
    pc := getcallerpc()
    
    // 在系统栈上执行创建逻辑
    systemstack(func() {
        newg := newproc1(fn, argp, siz, gp, pc)
        runqput(_p_, newg, true) // 放入运行队列
    })
}

func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) *g {
    // 1. 尝试从 P 的 gfree 列表获取 g
    // 2. 如果没有，则分配新的 g
    // 3. 初始化栈和调度信息
    // 4. 设置起始函数
    newg := gfget(_p_)
    if newg == nil {
        newg = malg(_StackMin)
        casgstatus(newg, _Gidle, _Gdead)
        allgadd(newg)
    }
    
    // 初始化 g 的栈和上下文
    totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize
    totalSize += -totalSize & (sys.SpAlign - 1)
    sp := newg.stack.hi - totalSize
    
    newg.sched.sp = sp
    newg.sched.pc = funcPC(goexit) + sys.PCQuantum
    newg.sched.g = guintptr(unsafe.Pointer(newg))
    gostartcallfn(&newg.sched, fn)
    
    casgstatus(newg, _Gdead, _Grunnable)
    newg.goid = int64(xadd64(&sched.goidgen, 1))
    
    return newg
}
```



### 调度过程

```go
// schedule 函数是调度的核心
func schedule() {
top:
    _g_ := getg()
    _g_.m.p.ptr().preempt = false

    // 1. 检查是否需要执行 GC
    if sched.gcwaiting != 0 {
        gcstopm()
        goto top
    }

    var gp *g
    var inheritTime bool

    // 2. 优先检查 runnext
    if gp == nil {
        if _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {
            lock(&sched.lock)
            gp = globrunqget(_g_.m.p.ptr(), 1)
            unlock(&sched.lock)
        }
    }
    
    // 3. 从本地队列获取
    if gp == nil {
        gp, inheritTime = runqget(_g_.m.p.ptr())
    }
    
    // 4. 从全局队列获取
    if gp == nil {
        gp, inheritTime = findrunnable() // 包含工作窃取逻辑
    }

    // 5. 执行 goroutine
    execute(gp, inheritTime)
}
```



###  销毁过程

```go
// goexit 是每个 goroutine 的退出点
func goexit(npc uintptr) {
    _g_ := getg()
    
    // 执行所有延迟函数
    for _g_._defer != nil {
        d := _g_._defer
        _g_._defer = d.link
        reflectcall(nil, unsafe.Pointer(d.fn), deferArgs(d), uint32(d.siz), uint32(d.siz))
        freedefer(d)
    }
    
    // 清理并回收 goroutine
    goexit1()
}

func goexit1() {
    _g_ := getg()
    casgstatus(_g_, _Grunning, _Gdead)
    
    // 清理 g 的各种状态
    _g_.m = nil
    _g_.lockedm = 0
    _g_.preemptStop = false
    _g_.paniconfault = false
    _g_._defer = nil
    _g_._panic = nil
    
    // 放回 P 的 gfree 列表供复用
    gfput(_g_.m.p.ptr(), _g_)
    schedule() // 继续调度其他 goroutine
}
```



##  协程与线程的比较

![image-20250529212857958](https://raw.githubusercontent.com/JoeyXXia/MyPictureData/main/image-20250529212857958.png)



### 详细分析

#### 内存效率

```go
// Goroutine 栈增长示例
func stackGrowth() {
    var arr [1000]int
    // 栈自动扩容，从 2KB 增长到足够大小
    recursiveCall(arr)
}

// 对比：线程需要预分配大栈空间
```

#### 调度开销

- **Goroutine**：用户态调度，无系统调用
- **Thread**：内核态调度，涉及系统调用和上下文切换

#### 扩展性

- **Goroutine**：M:N 模型，少量 OS 线程承载大量 goroutine
- **Thread**：1:1 模型，每个线程对应一个 OS 线程



## Go 语言的内存同步原语实现原理



###  Mutex 实现

```go
// sync/mutex.go
type Mutex struct {
    state int32  // 状态字段
    sema  uint32 // 信号量
}

const (
    mutexLocked = 1 << iota // 锁定状态
    mutexWoken              // 唤醒状态
    mutexStarving           // 饥饿状态
    mutexWaiterShift = iota // 等待者计数位移
)

func (m *Mutex) Lock() {
    // 快速路径：直接获取锁
    if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
        return
    }
    // 慢速路径：可能需要阻塞
    m.lockSlow()
}

func (m *Mutex) lockSlow() {
    var waitStartTime int64
    starving := false
    awoke := false
    iter := 0
    old := m.state
    
    for {
        // 正常模式下的自旋等待
        if old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) {
            if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 &&
                atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {
                awoke = true
            }
            runtime_doSpin()
            iter++
            old = m.state
            continue
        }
        
        // 准备新状态
        new := old
        if old&mutexStarving == 0 {
            new |= mutexLocked
        }
        if old&(mutexLocked|mutexStarving) != 0 {
            new += 1 << mutexWaiterShift
        }
        
        // 切换到饥饿模式
        if starving && old&mutexLocked != 0 {
            new |= mutexStarving
        }
        
        if awoke {
            new &^= mutexWoken
        }
        
        // 原子更新状态
        if atomic.CompareAndSwapInt32(&m.state, old, new) {
            if old&(mutexLocked|mutexStarving) == 0 {
                break // 获取到锁
            }
            
            // 等待信号量
            queueLifo := waitStartTime != 0
            if waitStartTime == 0 {
                waitStartTime = runtime_nanotime()
            }
            runtime_SemacquireMutex(&m.sema, queueLifo, 1)
            
            // 检查是否进入饥饿模式
            starving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs
            old = m.state
            
            if old&mutexStarving != 0 {
                // 饥饿模式下直接获取锁
                delta := int32(mutexLocked - 1<<mutexWaiterShift)
                if !starving || old>>mutexWaiterShift == 1 {
                    delta -= mutexStarving
                }
                atomic.AddInt32(&m.state, delta)
                break
            }
            awoke = true
            iter = 0
        } else {
            old = m.state
        }
    }
}
```



###  Channel 实现

```go
// runtime/chan.go
type hchan struct {
    qcount   uint           // 队列中的元素数量
    dataqsiz uint           // 循环队列大小
    buf      unsafe.Pointer // 数据缓冲区
    elemsize uint16         // 元素大小
    closed   uint32         // 关闭标志
    elemtype *_type         // 元素类型
    sendx    uint           // 发送索引
    recvx    uint           // 接收索引
    recvq    waitq          // 接收等待队列
    sendq    waitq          // 发送等待队列
    lock     mutex          // 保护字段的互斥锁
}

func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {
    // 检查 channel 是否为 nil
    if c == nil {
        if !block {
            return false
        }
        gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2)
        throw("unreachable")
    }

    // 快速路径：非阻塞且无法发送
    if !block && c.closed == 0 && full(c) {
        return false
    }

    lock(&c.lock)

    // 检查 channel 是否已关闭
    if c.closed != 0 {
        unlock(&c.lock)
        panic(plainError("send on closed channel"))
    }

    // 1. 直接发送给等待的接收者
    if sg := c.recvq.dequeue(); sg != nil {
        send(c, sg, ep, func() { unlock(&c.lock) }, 3)
        return true
    }

    // 2. 缓冲区有空间，直接发送
    if c.qcount < c.dataqsiz {
        qp := chanbuf(c, c.sendx)
        typedmemmove(c.elemtype, qp, ep)
        c.sendx++
        if c.sendx == c.dataqsiz {
            c.sendx = 0
        }
        c.qcount++
        unlock(&c.lock)
        return true
    }

    // 3. 阻塞等待
    if !block {
        unlock(&c.lock)
        return false
    }

    gp := getg()
    mysg := acquireSudog()
    mysg.releasetime = 0
    mysg.elem = ep
    mysg.waitlink = nil
    mysg.g = gp
    mysg.isSelect = false
    mysg.c = c
    gp.waiting = mysg
    gp.param = nil
    c.sendq.enqueue(mysg)
    
    // 阻塞当前 goroutine
    gopark(chanparkcommit, unsafe.Pointer(&c.lock), waitReasonChanSend, traceEvGoBlockSend, 2)
    
    // 被唤醒后的清理工作
    KeepAlive(ep)
    if mysg != gp.waiting {
        throw("G waiting list is corrupted")
    }
    gp.waiting = nil
    gp.activeStackChans = false
    closed := gp.param == nil
    gp.param = nil
    mysg.c = nil
    releaseSudog(mysg)
    if closed {
        if c.closed == 0 {
            throw("chansend: spurious wakeup")
        }
        panic(plainError("send on closed channel"))
    }
    return true
}
```



## 调度器的工作窃取算法及其优化、

### 工作窃取实现

```go
// runtime/proc.go - findrunnable 函数中的窃取逻辑
func findrunnable() (gp *g, inheritTime bool) {
    _g_ := getg()
    _p_ := _g_.m.p.ptr()

top:
    // 1. 本地队列检查
    if gp, inheritTime := runqget(_p_); gp != nil {
        return gp, inheritTime
    }

    // 2. 全局队列检查
    if sched.runqsize != 0 {
        lock(&sched.lock)
        gp := globrunqget(_p_, 0)
        unlock(&sched.lock)
        if gp != nil {
            return gp, false
        }
    }

    // 3. 网络轮询检查
    if netpollinited() && atomic.Load(&netpollWaiters) > 0 && atomic.Load64(&sched.lastpoll) != 0 {
        if list := netpoll(0); !list.empty() {
            gp := list.pop()
            injectglist(&list)
            casgstatus(gp, _Gwaiting, _Grunnable)
            return gp, false
        }
    }

    // 4. 工作窃取
    procs := uint32(gomaxprocs)
    ranTimer := false
    
    // 随机选择起始位置，避免总是从同一个 P 开始窃取
    if _g_.m.spinning || 2*atomic.Load(&sched.nmspinning) < procs-atomic.Load(&sched.npidle) {
        if !_g_.m.spinning {
            _g_.m.spinning = true
            atomic.Xadd(&sched.nmspinning, 1)
        }

        gp, inheritTime, tnow, w, newWork := stealWork(now)
        now = tnow
        if gp != nil {
            return gp, inheritTime
        }
        
        if newWork {
            goto top
        }
    }

    // 5. 停止自旋，准备休眠
    if _g_.m.spinning {
        _g_.m.spinning = false
        if int32(atomic.Xadd(&sched.nmspinning, -1)) < 0 {
            throw("findrunnable: negative nmspinning")
        }
    }

    // 6. 最后检查全局队列和网络
    if sched.runqsize != 0 {
        lock(&sched.lock)
        gp := globrunqget(_p_, 0)
        unlock(&sched.lock)
        if gp != nil {
            return gp, false
        }
    }

    // 7. 准备休眠
    stopm()
    goto top
}

func stealWork(now int64) (gp *g, inheritTime bool, rnow, pollUntil int64, newWork bool) {
    pp := getg().m.p.ptr()
    ranTimer := false

    const stealTries = 4
    for i := 0; i < stealTries; i++ {
        stealTimersOrRunNextG := i == stealTries-1

        for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() {
            if sched.gcwaiting != 0 {
                return nil, false, now, pollUntil, true
            }
            p2 := allp[enum.position()]
            if pp == p2 {
                continue
            }

            // 窃取一半的 goroutine
            if gp := runqsteal(pp, p2, stealTimersOrRunNextG); gp != nil {
                return gp, false, now, pollUntil, newWork
            }
        }
    }

    // 如果没有窃取到，检查定时器
    if ranTimer {
        if gp, inheritTime := runqget(pp); gp != nil {
            return gp, inheritTime, now, pollUntil, newWork
        }
    }

    return nil, false, now, pollUntil, newWork
}

func runqsteal(_p_, p2 *p, stealRunNextG bool) *g {
    t := _p_.runqtail
    n := runqgrab(p2, &_p_.runq, t, stealRunNextG)
    if n == 0 {
        return nil
    }
    n--
    gp := _p_.runq[(t+n)%uint32(len(_p_.runq))].ptr()
    if gp == nil {
        throw("runqsteal: inconsistent runq")
    }
    _p_.runqtail = t + n
    return gp
}
```



### 优化策略

#### 随机化窃取顺序

```go
type randomOrder struct {
    count uint32
    coprimes []uint32
}

func (ord *randomOrder) start(i uint32) randomEnum {
    return randomEnum{
        i:      i % ord.count,
        count:  ord.count,
        pos:    ord.coprimes[i%uint32(len(ord.coprimes))],
        inc:    ord.coprimes[(i+1)%uint32(len(ord.coprimes))],
    }
}
```

#### 批量窃取

- 每次窃取目标队列的一半
- 减少窃取频率，提高效率
- 保持负载均衡

#### 自旋优化

- 限制自旋的 M 数量
- 避免过度 CPU 消耗
- 在合适时机进入休眠



## 协程池实现与设计思路



### 设计目标

1. **复用 Goroutine**：减少创建/销毁开销
2. **控制并发数**：避免资源耗尽
3. **任务队列管理**：支持不同优先级
4. **优雅关闭**：等待任务完成后关闭
5. **监控统计**：提供运行时统计信息

### 核心实现

```go
package goroutinepool

import (
    "context"
    "errors"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
)

// Task 表示一个任务
type Task struct {
    Fn       func() error    // 任务函数
    Callback func(error)     // 回调函数
    Priority int             // 优先级（数字越小优先级越高）
    Deadline time.Time       // 截止时间
}

// Pool 协程池
type Pool struct {
    // 配置参数
    minWorkers    int32         // 最小工作协程数
    maxWorkers    int32         // 最大工作协程数
    keepAlive     time.Duration // 空闲协程存活时间
    queueSize     int           // 任务队列大小
    
    // 运行时状态
    currentWorkers int32        // 当前工作协程数
    idleWorkers    int32        // 空闲协程数
    runningTasks   int32        // 正在运行的任务数
    totalTasks     uint64       // 总任务数
    completedTasks uint64       // 完成任务数
    failedTasks    uint64       // 失败任务数
    
    // 同步原语
    taskQueue   chan *Task      // 任务队列
    workerQueue chan chan *Task // 工作协程队列
    quit        chan struct{}   // 关闭信号
    wg          sync.WaitGroup  // 等待所有协程结束
    mu          sync.RWMutex    // 保护共享状态
    once        sync.Once       // 确保只关闭一次
    
    // 状态标志
    closed int32 // 是否已关闭
}

// Config 配置选项
type Config struct {
    MinWorkers int           // 最小工作协程数，默认为 CPU 核数
    MaxWorkers int           // 最大工作协程数，默认为 CPU 核数 * 2
    KeepAlive  time.Duration // 空闲协程存活时间，默认 60 秒
    QueueSize  int           // 任务队列大小，默认 1000
}

// DefaultConfig 返回默认配置
func DefaultConfig() *Config {
    numCPU := runtime.NumCPU()
    return &Config{
        MinWorkers: numCPU,
        MaxWorkers: numCPU * 2,
        KeepAlive:  60 * time.Second,
        QueueSize:  1000,
    }
}

// NewPool 创建新的协程池
func NewPool(config *Config) (*Pool, error) {
    if config == nil {
        config = DefaultConfig()
    }
    
    if config.MinWorkers <= 0 || config.MaxWorkers <= 0 {
        return nil, errors.New("workers count must be positive")
    }
    
    if config.MinWorkers > config.MaxWorkers {
        return nil, errors.New("minWorkers cannot be greater than maxWorkers")
    }
    
    pool := &Pool{
        minWorkers:     int32(config.MinWorkers),
        maxWorkers:     int32(config.MaxWorkers),
        keepAlive:      config.KeepAlive,
        queueSize:      config.QueueSize,
        taskQueue:      make(chan *Task, config.QueueSize),
        workerQueue:    make(chan chan *Task, config.MaxWorkers),
        quit:           make(chan struct{}),
        currentWorkers: 0,
        idleWorkers:    0,
    }
    
    // 启动最小数量的工作协程
    for i := 0; i < config.MinWorkers; i++ {
        pool.createWorker()
    }
    
    // 启动调度器
    go pool.dispatcher()
    
    return pool, nil
}

// Submit 提交任务到协程池
func (p *Pool) Submit(task *Task) error {
    return p.SubmitWithContext(context.Background(), task)
}

// SubmitWithContext 带上下文提交任务
func (p *Pool) SubmitWithContext(ctx context.Context, task *Task) error {
    if atomic.LoadInt32(&p.closed) == 1 {
        return errors.New("pool is closed")
    }
    
    if task == nil || task.Fn == nil {
        return errors.New("task or task function cannot be nil")
    }
    
    atomic.AddUint64(&p.totalTasks, 1)
    
    select {
    case p.taskQueue <- task:
        return nil
    case <-ctx.Done():
        return ctx.Err()
    case <-p.quit:
        return errors.New("pool is shutting down")
    }
}

// SubmitFunc 提交函数任务的便捷方法
func (p *Pool) SubmitFunc(fn func() error) error {
    return p.Submit(&Task{Fn: fn})
}

// dispatcher 任务分发器
func (p *Pool) dispatcher() {
    for {
        select {
        case task := <-p.taskQueue:
            // 检查任务是否过期
            if !task.Deadline.IsZero() && time.Now().After(task.Deadline) {
                atomic.AddUint64(&p.failedTasks, 1)
                if task.Callback != nil {
                    go task.Callback(errors.New("task deadline exceeded"))
                }
                continue
            }
            
            // 尝试获取空闲工作协程
            select {
            case workerChan := <-p.workerQueue:
                // 有空闲工作协程，直接分配任务
                select {
                case workerChan <- task:
                default:
                    // 工作协程可能已经退出，重新排队任务
                    select {
                    case p.taskQueue <- task:
                    default:
                        // 队列满了，丢
```
